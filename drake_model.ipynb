{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5cc61a-8f99-41a7-934b-5843a7e54086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f90d156-ecce-4df8-9318-7970c51d4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('drake_lyric_data.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# drop non-numerical columns except for 'lyrics'\n",
    "audio_features = df.drop(columns=['name', 'album', 'year', 'popularity', 'lyrics'])\n",
    "lyrics = df['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2b44c4-f21e-4948-96a7-44ace388fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize audio features\n",
    "scaler = MinMaxScaler()\n",
    "audio_features_scaled = scaler.fit_transform(audio_features)\n",
    "\n",
    "# tokenize the lyrics\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lyrics)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# convert lyrics to sequences\n",
    "input_sequences = []\n",
    "for line in lyrics:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f311ce12-a8af-42d0-852e-770355829dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into predictors and labels\n",
    "X_text, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# repeat audio features to match the number of sequences\n",
    "repeated_audio_features = np.repeat(audio_features_scaled, len(X_text) // len(audio_features_scaled) + 1, axis=0)[:len(X_text)]\n",
    "X_audio = np.repeat(repeated_audio_features[:, np.newaxis, :], X_text.shape[1], axis=1)\n",
    "\n",
    "# combine text and audio features\n",
    "X = np.concatenate([X_text.reshape(X_text.shape[0], X_text.shape[1], 1), X_audio], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc43c4-b99e-4593-a947-2c7f72d1c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(max_sequence_len-1, X.shape[2])))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "history = model.fit(X, y, epochs=100, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
